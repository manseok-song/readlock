"""ì•„ì¹´ì´ë¸Œ êµ¬ì¡°í™” ëª¨ë“ˆ

ì „ì‚¬ ê²°ê³¼ì™€ ê´€ë ¨ íŒŒì¼ë“¤ì„ ì²´ê³„ì ì¸ í´ë” êµ¬ì¡°ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

ì¶œë ¥ êµ¬ì¡°:
ğŸ“ election_archive/
â””â”€â”€ ğŸ“ {timestamp}_{title}/
    â”œâ”€â”€ ğŸ“¹ original.mp4
    â”œâ”€â”€ ğŸ“º subtitled.mp4
    â”œâ”€â”€ ğŸ“„ transcript.srt
    â”œâ”€â”€ ğŸ“„ transcript.vtt
    â”œâ”€â”€ ğŸ“„ transcript.txt
    â”œâ”€â”€ ğŸ“„ transcript.docx
    â”œâ”€â”€ ğŸ“Š metadata.json
    â”œâ”€â”€ ğŸ“Š quality_report.json
    â””â”€â”€ ğŸ“ rag_data/
        â”œâ”€â”€ knowledge_base.json
        â”œâ”€â”€ candidates.json
        â””â”€â”€ policies.json
"""

import json
import shutil
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional, TYPE_CHECKING

if TYPE_CHECKING:
    from src.stt.base import TranscriptionResult
    from src.rag.knowledge_builder import KnowledgeBase
    from src.quality.scorer import QualityScore


@dataclass
class ArchiveResult:
    """ì•„ì¹´ì´ë¸Œ ê²°ê³¼"""
    path: Path                              # ì•„ì¹´ì´ë¸Œ í´ë” ê²½ë¡œ
    files: dict[str, Path] = field(default_factory=dict)  # íŒŒì¼ ëª©ë¡
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())

    @property
    def original_video(self) -> Optional[Path]:
        return self.files.get("original_video")

    @property
    def subtitled_video(self) -> Optional[Path]:
        return self.files.get("subtitled_video")

    @property
    def srt_file(self) -> Optional[Path]:
        return self.files.get("srt")

    @property
    def docx_file(self) -> Optional[Path]:
        return self.files.get("docx")

    def to_dict(self) -> dict:
        return {
            "path": str(self.path),
            "files": {k: str(v) for k, v in self.files.items()},
            "created_at": self.created_at,
        }


class ArchiveOrganizer:
    """ì•„ì¹´ì´ë¸Œ êµ¬ì¡°í™” ê´€ë¦¬ì"""

    def __init__(self, base_dir: str | Path = "election_archive"):
        """
        Args:
            base_dir: ì•„ì¹´ì´ë¸Œ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        """
        self.base_dir = Path(base_dir)

    def _generate_folder_name(
        self,
        title: Optional[str] = None,
        election_type: Optional[str] = None,
        region: Optional[str] = None
    ) -> str:
        """í´ë” ì´ë¦„ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if title:
            # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
            safe_title = "".join(
                c if c.isalnum() or c in "_ -" else "_"
                for c in title
            )
            return f"{timestamp}_{safe_title}"

        parts = [timestamp]
        if election_type:
            parts.append(election_type)
        if region:
            parts.append(region)

        return "_".join(parts)

    def _rollback_files(self, files: dict[str, Path], archive_path: Path):
        """íŠ¸ëœì­ì…˜ ë¡¤ë°±: ë³µì‚¬ëœ íŒŒì¼ë“¤ ì‚­ì œ"""
        import logging
        logger = logging.getLogger(__name__)

        for key, file_path in files.items():
            try:
                if file_path.exists():
                    file_path.unlink()
                    logger.info(f"ë¡¤ë°±: {file_path} ì‚­ì œë¨")
            except Exception as e:
                logger.warning(f"ë¡¤ë°± ì‹¤íŒ¨ ({file_path}): {e}")

        # rag_data ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹œë„
        rag_dir = archive_path / "rag_data"
        if rag_dir.exists():
            try:
                shutil.rmtree(rag_dir)
            except Exception:
                pass

        # ë¹ˆ ì•„ì¹´ì´ë¸Œ í´ë” ì‚­ì œ ì‹œë„
        try:
            if archive_path.exists() and not any(archive_path.iterdir()):
                archive_path.rmdir()
                logger.info(f"ë¡¤ë°±: ë¹ˆ í´ë” {archive_path} ì‚­ì œë¨")
        except Exception:
            pass

    def organize(
        self,
        original_video: Optional[str | Path] = None,
        subtitled_video: Optional[str | Path] = None,
        transcription: Optional["TranscriptionResult"] = None,
        srt_file: Optional[str | Path] = None,
        vtt_file: Optional[str | Path] = None,
        txt_file: Optional[str | Path] = None,
        docx_file: Optional[str | Path] = None,
        knowledge_base: Optional["KnowledgeBase"] = None,
        quality_score: Optional["QualityScore"] = None,
        title: Optional[str] = None,
        metadata: Optional[dict] = None,
        copy_files: bool = True
    ) -> ArchiveResult:
        """
        ì•„ì¹´ì´ë¸Œ êµ¬ì¡°í™” (íŠ¸ëœì­ì…˜ ì§€ì›)

        Args:
            original_video: ì›ë³¸ ì˜ìƒ ê²½ë¡œ
            subtitled_video: ìë§‰ì´ ì‚½ì…ëœ ì˜ìƒ ê²½ë¡œ
            transcription: ì „ì‚¬ ê²°ê³¼
            srt_file: SRT ìë§‰ íŒŒì¼ ê²½ë¡œ
            vtt_file: VTT ìë§‰ íŒŒì¼ ê²½ë¡œ
            txt_file: í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            docx_file: DOCX ë¬¸ì„œ ê²½ë¡œ
            knowledge_base: ì„ ê±° ì§€ì‹ ë² ì´ìŠ¤
            quality_score: í’ˆì§ˆ ì ìˆ˜
            title: ì•„ì¹´ì´ë¸Œ ì œëª©
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            copy_files: Trueë©´ íŒŒì¼ ë³µì‚¬, Falseë©´ ì´ë™

        Returns:
            ArchiveResult

        Raises:
            ArchiveError: ì•„ì¹´ì´ë¸Œ ì‹¤íŒ¨ ì‹œ (ë¡¤ë°± ìˆ˜í–‰)
        """
        import logging
        logger = logging.getLogger(__name__)

        # í´ë” ì´ë¦„ ìƒì„±
        election_type = None
        region = None
        if knowledge_base:
            election_type = knowledge_base.election_type
            region = knowledge_base.region

        folder_name = self._generate_folder_name(title, election_type, region)
        archive_path = self.base_dir / folder_name

        files = {}
        file_operation = shutil.copy2 if copy_files else shutil.move

        try:
            archive_path.mkdir(parents=True, exist_ok=True)

            # 1. ì›ë³¸ ì˜ìƒ ì €ì¥
            if original_video:
                original_video = Path(original_video)
                if original_video.exists():
                    dest = archive_path / f"original{original_video.suffix}"
                    file_operation(str(original_video), str(dest))
                    files["original_video"] = dest
                    logger.info(f"ì›ë³¸ ì˜ìƒ ì €ì¥: {dest}")

            # 2. ìë§‰ ì˜ìƒ ì €ì¥
            if subtitled_video:
                subtitled_video = Path(subtitled_video)
                if subtitled_video.exists():
                    dest = archive_path / f"subtitled{subtitled_video.suffix}"
                    file_operation(str(subtitled_video), str(dest))
                    files["subtitled_video"] = dest
                    logger.info(f"ìë§‰ ì˜ìƒ ì €ì¥: {dest}")

            # 3. ìë§‰ íŒŒì¼ ì €ì¥
            for file_path, key, default_name in [
                (srt_file, "srt", "transcript.srt"),
                (vtt_file, "vtt", "transcript.vtt"),
                (txt_file, "txt", "transcript.txt"),
                (docx_file, "docx", "transcript.docx"),
            ]:
                if file_path:
                    file_path = Path(file_path)
                    if file_path.exists():
                        dest = archive_path / default_name
                        file_operation(str(file_path), str(dest))
                        files[key] = dest
                        logger.info(f"{key} íŒŒì¼ ì €ì¥: {dest}")

            # 4. ì „ì‚¬ ê²°ê³¼ JSON ì €ì¥
            if transcription:
                json_path = archive_path / "transcript.json"
                with open(json_path, "w", encoding="utf-8") as f:
                    # Pydantic v2: model_dump(), Pydantic v1: dict()
                    if hasattr(transcription, "model_dump"):
                        data = transcription.model_dump()
                    else:
                        data = transcription.dict()
                    json.dump(data, f, ensure_ascii=False, indent=2)
                files["transcript_json"] = json_path

            # 5. RAG ë°ì´í„° ì €ì¥
            if knowledge_base:
                rag_dir = archive_path / "rag_data"
                rag_dir.mkdir(exist_ok=True)

                # ì „ì²´ ì§€ì‹ ë² ì´ìŠ¤
                kb_path = rag_dir / "knowledge_base.json"
                with open(kb_path, "w", encoding="utf-8") as f:
                    json.dump(knowledge_base.to_dict(), f, ensure_ascii=False, indent=2)
                files["knowledge_base"] = kb_path

                # í›„ë³´ì ì •ë³´
                if knowledge_base.candidates:
                    candidates_path = rag_dir / "candidates.json"
                    candidates_data = [
                        {
                            "name": c.name,
                            "party": c.party,
                            "number": c.number,
                            "region": c.region,
                            "position": c.position,
                            "aliases": c.aliases,
                        }
                        for c in knowledge_base.candidates
                    ]
                    with open(candidates_path, "w", encoding="utf-8") as f:
                        json.dump(candidates_data, f, ensure_ascii=False, indent=2)
                    files["candidates"] = candidates_path

                # ì •ì±… ì •ë³´
                if knowledge_base.policies:
                    policies_path = rag_dir / "policies.json"
                    policies_data = [
                        {
                            "name": p.name,
                            "description": p.description,
                            "candidate": p.candidate,
                            "category": p.category,
                            "keywords": p.keywords,
                        }
                        for p in knowledge_base.policies
                    ]
                    with open(policies_path, "w", encoding="utf-8") as f:
                        json.dump(policies_data, f, ensure_ascii=False, indent=2)
                    files["policies"] = policies_path

            # 6. í’ˆì§ˆ ë¦¬í¬íŠ¸ ì €ì¥
            if quality_score:
                quality_path = archive_path / "quality_report.json"
                with open(quality_path, "w", encoding="utf-8") as f:
                    json.dump(quality_score.to_dict(), f, ensure_ascii=False, indent=2)
                files["quality_report"] = quality_path

            # 7. ë©”íƒ€ë°ì´í„° ì €ì¥
            full_metadata = {
                "title": title,
                "created_at": datetime.now().isoformat(),
                "files": {k: str(v.name) for k, v in files.items()},
            }
            if metadata:
                full_metadata.update(metadata)
            if knowledge_base:
                full_metadata["election_type"] = knowledge_base.election_type
                full_metadata["region"] = knowledge_base.region
                full_metadata["election_date"] = knowledge_base.election_date
            if quality_score:
                full_metadata["quality_grade"] = quality_score.grade
                full_metadata["quality_score"] = round(quality_score.total, 4)

            metadata_path = archive_path / "metadata.json"
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(full_metadata, f, ensure_ascii=False, indent=2)
            files["metadata"] = metadata_path

            logger.info(f"ì•„ì¹´ì´ë¸Œ ì™„ë£Œ: {archive_path}")
            return ArchiveResult(
                path=archive_path,
                files=files,
            )

        except Exception as e:
            # íŠ¸ëœì­ì…˜ ë¡¤ë°±
            logger.error(f"ì•„ì¹´ì´ë¸Œ ì‹¤íŒ¨, ë¡¤ë°± ìˆ˜í–‰: {e}")
            self._rollback_files(files, archive_path)
            raise RuntimeError(f"ì•„ì¹´ì´ë¸Œ ìƒì„± ì‹¤íŒ¨: {e}") from e

    def list_archives(self) -> list[dict]:
        """ì•„ì¹´ì´ë¸Œ ëª©ë¡ ì¡°íšŒ"""
        if not self.base_dir.exists():
            return []

        archives = []
        for folder in sorted(self.base_dir.iterdir(), reverse=True):
            if folder.is_dir():
                metadata_path = folder / "metadata.json"
                if metadata_path.exists():
                    with open(metadata_path, "r", encoding="utf-8") as f:
                        metadata = json.load(f)
                    metadata["folder"] = str(folder)
                    archives.append(metadata)
                else:
                    archives.append({
                        "folder": str(folder),
                        "title": folder.name,
                    })

        return archives

    def load_archive(self, folder_path: str | Path) -> Optional[ArchiveResult]:
        """ì•„ì¹´ì´ë¸Œ ë¡œë“œ"""
        folder_path = Path(folder_path)
        if not folder_path.exists():
            return None

        files = {}
        for file in folder_path.iterdir():
            if file.is_file():
                if file.name.startswith("original"):
                    files["original_video"] = file
                elif file.name.startswith("subtitled"):
                    files["subtitled_video"] = file
                elif file.suffix == ".srt":
                    files["srt"] = file
                elif file.suffix == ".vtt":
                    files["vtt"] = file
                elif file.suffix == ".txt":
                    files["txt"] = file
                elif file.suffix == ".docx":
                    files["docx"] = file
                elif file.name == "transcript.json":
                    files["transcript_json"] = file
                elif file.name == "quality_report.json":
                    files["quality_report"] = file
                elif file.name == "metadata.json":
                    files["metadata"] = file

        rag_dir = folder_path / "rag_data"
        if rag_dir.exists():
            if (rag_dir / "knowledge_base.json").exists():
                files["knowledge_base"] = rag_dir / "knowledge_base.json"
            if (rag_dir / "candidates.json").exists():
                files["candidates"] = rag_dir / "candidates.json"
            if (rag_dir / "policies.json").exists():
                files["policies"] = rag_dir / "policies.json"

        # created_at ì¶”ì¶œ
        created_at = datetime.now().isoformat()
        if "metadata" in files:
            with open(files["metadata"], "r", encoding="utf-8") as f:
                metadata = json.load(f)
                created_at = metadata.get("created_at", created_at)

        return ArchiveResult(
            path=folder_path,
            files=files,
            created_at=created_at,
        )


def create_archive(
    original_video: Optional[str | Path] = None,
    base_dir: str = "election_archive",
    **kwargs
) -> ArchiveResult:
    """ì•„ì¹´ì´ë¸Œ ìƒì„± í—¬í¼ í•¨ìˆ˜"""
    organizer = ArchiveOrganizer(base_dir)
    return organizer.organize(original_video=original_video, **kwargs)
