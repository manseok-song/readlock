"""Gemini STT ì—”ì§„ - Google Gemini 3 Flash ê¸°ë°˜ ì „ì‚¬ ë° í™”ìë¶„ë¦¬"""

import json
import os
import re
import subprocess
import tempfile
import time
import random
from pathlib import Path
from typing import Optional, List

import google.generativeai as genai
from google.api_core import exceptions as google_exceptions
from pydantic import BaseModel

from src.stt.base import STTEngine, TranscriptionResult, Segment
from src.audio.chunker import AudioChunker, AudioChunk, ChunkConfig, merge_transcriptions


# GCS ë²„í‚· ì„¤ì •
GCS_BUCKET_NAME = os.getenv("GCS_BUCKET_NAME", "video-to-text-uploads-causal-binder")

# ì²­í¬ ë¶„í•  ì„ê³„ê°’ (ì´ˆ)
# - ì˜ìƒ ëª¨ë“œ: 30ë¶„ (Gemini 45ë¶„ ì œí•œ, ì•ˆì „ ë§ˆì§„)
# - ì˜¤ë””ì˜¤ ëª¨ë“œ: 4ì‹œê°„ (Gemini 8.4ì‹œê°„ ì œí•œ, ì•ˆì „ ë§ˆì§„)
VIDEO_CHUNK_THRESHOLD_SECONDS = 1800   # 30ë¶„
AUDIO_CHUNK_THRESHOLD_SECONDS = 14400  # 4ì‹œê°„


class GeminiConfig(BaseModel):
    """Gemini STT ì„¤ì •"""
    model: str = "gemini-3-flash-preview"  # Gemini 3 Flash (2026-02)
    api_key: Optional[str] = None
    max_retries: int = 3
    timeout: int = 600  # ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ìœ„í•´ 10ë¶„ìœ¼ë¡œ ì¦ê°€
    use_gcs: bool = True  # GCS ì‚¬ìš© ì—¬ë¶€
    enable_chunking: bool = True  # ê¸´ ì˜¤ë””ì˜¤ ìë™ ë¶„í•  í™œì„±í™”
    use_video_mode: bool = False  # ì˜ìƒ ëª¨ë“œ (í™”ë©´ í…ìŠ¤íŠ¸ ì¸ì‹ í¬í•¨)
    # Gemini 3 ì „ìš© íŒŒë¼ë¯¸í„°
    thinking_level: str = "medium"  # minimal, low, medium, high (í™”ì ë¶„ë¦¬ì— íš¨ê³¼ì )
    media_resolution: str = "low"  # low, medium, high (TV ì½˜í…ì¸ ëŠ” lowë¡œ ì¶©ë¶„)
    temperature: float = 1.0  # Gemini 3 ê¶Œì¥ê°’ (ë‚®ìœ¼ë©´ ì˜ˆê¸°ì¹˜ ì•Šì€ ë™ì‘)


class GeminiSTT(STTEngine):
    """Gemini ê¸°ë°˜ STT ì—”ì§„"""

    def __init__(self, config: Optional[GeminiConfig] = None):
        self.config = config or GeminiConfig()
        self._setup_api()

    def _setup_api(self) -> None:
        """API ì„¤ì •"""
        api_key = self.config.api_key or os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError(
                "GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                ".env íŒŒì¼ì— GEMINI_API_KEY=your-keyë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ "
                "í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”."
            )
        genai.configure(api_key=api_key)

    @property
    def name(self) -> str:
        return "gemini"

    @property
    def supports_diarization(self) -> bool:
        return True

    def _build_prompt(
        self,
        num_speakers: Optional[int],
        language: str,
        proper_nouns: Optional[List[str]] = None,
        use_video_mode: bool = False,
        remove_fillers: bool = False,
        election_debate_mode: bool = False
    ) -> str:
        """ì „ì‚¬ í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            num_speakers: í™”ì ìˆ˜ íŒíŠ¸
            language: ì–¸ì–´ ì½”ë“œ
            proper_nouns: ê³ ìœ ëª…ì‚¬/ì¸ëª… íŒíŠ¸ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["í™©ê¸ˆì„", "ì‚¼ì„±ì „ì", "GPT-4"])
            use_video_mode: ì˜ìƒ ëª¨ë“œ (í™”ë©´ í…ìŠ¤íŠ¸ ì¸ì‹ í¬í•¨)
            remove_fillers: í•„ëŸ¬(ì–´, ìŒ, ê·¸) ë° ë”ë“¬ê±°ë¦¼ ì œê±° ì—¬ë¶€
            election_debate_mode: ì„ ê±° í† ë¡ íšŒ ëª¨ë“œ (í™”ìë¥¼ ì‚¬íšŒì/í›„ë³´ëª…ìœ¼ë¡œ êµ¬ë¶„)
        """
        speaker_hint = ""
        if num_speakers:
            speaker_hint = f"ì´ ì˜¤ë””ì˜¤ì—ëŠ” ì•½ {num_speakers}ëª…ì˜ í™”ìê°€ ìˆìŠµë‹ˆë‹¤. "

        # ê³ ìœ ëª…ì‚¬ íŒíŠ¸ ì„¹ì…˜ (í™”ì ì´ë¦„ ê°•ì¡°)
        proper_noun_section = ""
        if proper_nouns and len(proper_nouns) > 0:
            noun_list = ", ".join(proper_nouns)
            proper_noun_section = f"""
## âš ï¸ í™”ì/ê³ ìœ ëª…ì‚¬ íŒíŠ¸ (í•„ìˆ˜ ì ìš©!)
ë‹¤ìŒ ì´ë¦„/ìš©ì–´ë“¤ì´ **ì´ë¯¸ í™•ì¸**ë˜ì—ˆìŠµë‹ˆë‹¤. **ë°˜ë“œì‹œ** ì•„ë˜ í‘œê¸°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:
### ğŸ“› í™•ì¸ëœ ì´ë¦„/ìš©ì–´: {noun_list}

### í™”ì ì´ë¦„ ì ìš© ê·œì¹™ (ì¤‘ìš”!)
1. **ë°œìŒì´ ë¹„ìŠ·í•˜ë©´ íŒíŠ¸ ì´ë¦„ ì‚¬ìš©**:
   - íŒíŠ¸: "ë°•ê°•ì‚°" â†’ "ë°•ê´‘ì„ ", "ë°•ê°•ì„ ", "ë°• ê°•ì‚°" ëª¨ë‘ "ë°•ê°•ì‚°"ìœ¼ë¡œ í‘œê¸°
   - íŒíŠ¸: "í™©ê¸ˆì„" â†’ "í™˜ê¸ˆì„", "í™© ê¸ˆì„", "í•œê¸ˆì„" ëª¨ë‘ "í™©ê¸ˆì„"ìœ¼ë¡œ í‘œê¸°

2. **í™”ì ë ˆì´ë¸”ì— íŒíŠ¸ ì ìš©**:
   - íŒíŠ¸ì— ì¸ëª…ì´ ìˆìœ¼ë©´ speaker í•„ë“œì— í•´ë‹¹ ì´ë¦„ ì‚¬ìš©
   - ì˜ˆ: íŒíŠ¸ì— "ë°•ê°•ì‚°"ì´ ìˆê³ , ëˆ„êµ°ê°€ "ì €ëŠ” ë°•ê°•ì‚°ì…ë‹ˆë‹¤"ë¼ê³  í•˜ë©´ â†’ speaker: "ë°•ê°•ì‚°"

3. **ì¸ëª… í‘œê¸° ê·œì¹™**:
   - ë„ì–´ì“°ê¸° ì—†ì´ ë¶™ì—¬ì„œ í‘œê¸° (ì˜ˆ: "ë°•ê°•ì‚°", "ê¹€ì² ìˆ˜")
   - ì ˆëŒ€ë¡œ "ë°• ê°•ì‚°", "ë°•ê°• ì‚°" ì²˜ëŸ¼ ë„ì–´ì“°ì§€ ë§ ê²ƒ

4. **âš ï¸ í™˜ê° ë°©ì§€ (ë§¤ìš° ì¤‘ìš”!)**:
   - í™•ì‹¤í•˜ì§€ ì•Šì€ ê³ ìœ ëª…ì‚¬ëŠ” **"[í™•ì¸ ë¶ˆê°€]"**ë¡œ í‘œê¸°
   - ë°œìŒì´ ë¶ˆëª…í™•í•´ë„ **ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”**
   - íŒíŠ¸ì— ì—†ëŠ” ì´ë¦„ì´ ë“¤ë¦¬ë©´ ë“¤ë¦¬ëŠ” ëŒ€ë¡œ í‘œê¸° (ì§€ì–´ë‚´ì§€ ë§ ê²ƒ)
"""

        # ì˜ìƒ ëª¨ë“œ: í™”ë©´ í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì „ì‚¬ ë³´ì •
        video_mode_section = ""
        if use_video_mode:
            video_mode_section = """
## í™”ë©´ í…ìŠ¤íŠ¸ ì°¸ê³  (ë³´ì •ìš©)
ì´ê²ƒì€ ì˜ìƒ íŒŒì¼ì…ë‹ˆë‹¤. **ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜**í•˜ë˜, í™”ë©´ì— í‘œì‹œëœ í…ìŠ¤íŠ¸ë¥¼ **ì°¸ê³ **í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì´ì„¸ìš”:

1. **í™”ì ì´ë¦„ í™•ì¸**: í™”ë©´ì— í™”ì ì´ë¦„ì´ í‘œì‹œë˜ë©´ í•´ë‹¹ ì´ë¦„ì„ í™”ì ë ˆì´ë¸”ë¡œ ì‚¬ìš©
   - ì˜ˆ: í™”ë©´ì— "í™ê¸¸ë™ êµìˆ˜"ê°€ ë³´ì´ê³  ê·¸ ì‚¬ëŒì´ ë§í•˜ë©´ â†’ speaker: "í™ê¸¸ë™"
   - ì´ë¦„ì´ ì•ˆ ë³´ì´ë©´ "í™”ì1", "í™”ì2" ì‚¬ìš©

2. **ì „ë¬¸ ìš©ì–´/ê³ ìœ ëª…ì‚¬ ë³´ì •**: í™”ë©´ ìë§‰ì— ë‚˜ì˜¨ ìš©ì–´ë‚˜ ì´ë¦„ì„ ì°¸ê³ í•˜ì—¬ ìŒì„± ì¸ì‹ ê²°ê³¼ ë³´ì •
   - í™”ë©´ì— "GPT-4o"ê°€ ë³´ì´ëŠ”ë° ìŒì„±ì´ "GPT í¬ì˜¤"ë¡œ ë“¤ë¦¬ë©´ â†’ "GPT-4o"ë¡œ í‘œê¸°
   - í™”ë©´ì— "ì‚¼ì„±ì „ì"ê°€ ë³´ì´ëŠ”ë° ìŒì„±ì´ "ì‚¼ì„± ì „ì"ë¡œ ë“¤ë¦¬ë©´ â†’ "ì‚¼ì„±ì „ì"ë¡œ í‘œê¸°

3. **ë©”ì¸ì€ ìŒì„±**: ê¸°ë³¸ì ìœ¼ë¡œ ìŒì„±ì„ ì „ì‚¬í•˜ê³ , í™”ë©´ í…ìŠ¤íŠ¸ëŠ” **ë³´ì • ì°¸ê³ ìš©**
   - í™”ë©´ ìë§‰ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ê³ , ì‹¤ì œ ë°œí™” ë‚´ìš©ì„ ì „ì‚¬
   - í™”ë©´ ì •ë³´ëŠ” ì² ì/í‘œê¸° í™•ì¸ì—ë§Œ í™œìš©
"""

        # í•„ëŸ¬ ì œê±° ëª¨ë“œ: ë”ë“¬ê±°ë¦¼, í•„ëŸ¬ì›Œë“œ ì •ë¦¬
        filler_removal_section = ""
        if remove_fillers:
            filler_removal_section = """
## í•„ëŸ¬ ë° ë”ë“¬ê±°ë¦¼ ì œê±° (ì¤‘ìš”!)
ì „ì‚¬ ì‹œ ë‹¤ìŒ ê·œì¹™ì„ ì ìš©í•˜ì—¬ **ê¹”ë”í•œ ë¬¸ì¥**ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”:

1. **í•„ëŸ¬ì›Œë“œ ì œê±°**: "ì–´", "ìŒ", "ê·¸", "ì €ê¸°", "ë­", "ì´ì œ", "ê·¸ëŸ¬ë‹ˆê¹Œ" ë“± ì˜ë¯¸ ì—†ëŠ” ì¶”ì„ìƒˆ ì‚­ì œ
   - ì›ë³¸: "ì–´... ê·¸ëŸ¬ë‹ˆê¹Œ ìŒ... ì œê°€ ë§ì”€ë“œë¦¬ê³  ì‹¶ì€ ê±´..."
   - ì •ë¦¬: "ì œê°€ ë§ì”€ë“œë¦¬ê³  ì‹¶ì€ ê±´..."

2. **ë”ë“¬ê±°ë¦¼/ë°˜ë³µ ì •ë¦¬**: ë§ì„ ë”ë“¬ê±°ë‚˜ ë°˜ë³µí•œ ë¶€ë¶„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬
   - ì›ë³¸: "ê·¸, ê·¸, ê·¸ë˜ì„œ ì €, ì €í¬ê°€..."
   - ì •ë¦¬: "ê·¸ë˜ì„œ ì €í¬ê°€..."
   - ì›ë³¸: "ì´ê²Œ ë­ëƒë©´ì€, ë­ëƒë©´ì€..."
   - ì •ë¦¬: "ì´ê²Œ ë­ëƒë©´..."

3. **ì˜ë¯¸ ë³´ì¡´**: ë‚´ìš©ì„ ì§€ì–´ë‚´ê±°ë‚˜ ë°”ê¾¸ì§€ ë§ê³ , í™”ìê°€ ì „ë‹¬í•˜ë ¤ë˜ **ì›ë˜ ì˜ë¯¸ë§Œ ë³´ì¡´**
   - ë¶ˆí•„ìš”í•œ ë°˜ë³µê³¼ ë§ì„¤ì„ë§Œ ì œê±°
   - ì‹¤ì œ ë°œí™” ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€

4. **ë¬¸ì¥ ì™„ì„±**: ëŠì–´ì§„ ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ ì •ë¦¬
   - ì›ë³¸: "ê·¸ë˜ì„œ ì´ê²Œ, ì•„ ë­ë”ë¼, ì´ê²Œ ì¤‘ìš”í•œ ê²Œ..."
   - ì •ë¦¬: "ê·¸ë˜ì„œ ì´ê²Œ ì¤‘ìš”í•œ ê²Œ..."
"""

        # ì„ ê±° í† ë¡ íšŒ ëª¨ë“œ: ì†ê¸°ë¡ ìŠ¤íƒ€ì¼ + ì •ì±…ëª… ì •í™• ì „ì‚¬
        election_debate_section = ""
        if election_debate_mode:
            # ë¹„ë””ì˜¤ ëª¨ë“œì—ì„œ í™”ë©´ í…ìŠ¤íŠ¸ ì°¸ê³  ì•ˆë‚´
            screen_text_hint = ""
            if use_video_mode:
                screen_text_hint = """
### ğŸ“º í™”ë©´ í…ìŠ¤íŠ¸ í™œìš© (ë¹„ë””ì˜¤ ëª¨ë“œ)
ì˜ìƒ í™”ë©´ì— í‘œì‹œë˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì ê·¹ í™œìš©í•˜ì„¸ìš”:
- í™”ë©´ì— ë‚˜ì˜¤ëŠ” **ì •ì±…ëª…, ê³µì•½, ë²•ì•ˆëª…** â†’ ì •í™•í•œ í‘œê¸° ì°¸ê³ 
- ìë§‰/í•˜ë‹¨ í…ìŠ¤íŠ¸ì— í‘œì‹œëœ **í›„ë³´ ì´ë¦„, ì†Œì†** â†’ í™”ì ì‹ë³„ì— í™œìš©
- ì¸í¬ê·¸ë˜í”½ì˜ **ìˆ«ì, ë‚ ì§œ, ì˜ˆì‚°** â†’ ì •í™•í•œ ìˆ˜ì¹˜ í™•ì¸
"""

            election_debate_section = f"""
## ğŸ—³ï¸ ì„ ê±° í† ë¡ íšŒ ì†ê¸°ë¡ ëª¨ë“œ (í•„ìˆ˜!)
{screen_text_hint}
### 1. ì†ê¸°ë¡ ìŠ¤íƒ€ì¼ ì „ì‚¬ ì›ì¹™
**ë”ë“¬ê±°ë¦¼, ë§ì„¤ì„, ë°˜ë³µì„ ê·¸ëŒ€ë¡œ ìœ ì§€**í•˜ì„¸ìš”. ì†ê¸°ë¡ì²˜ëŸ¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤:

- âœ… ì˜¬ë°”ë¥¸ ì˜ˆ: "ì–´... ê·¸, ê·¸ëŸ¬ë‹ˆê¹Œ ì œê°€ ë§ì”€ë“œë¦¬ê³  ì‹¶ì€ ê±´..."
- âŒ ì˜ëª»ëœ ì˜ˆ: "ì œê°€ ë§ì”€ë“œë¦¬ê³  ì‹¶ì€ ê±´..." (ì •ë¦¬ë¨)
- âœ… ì˜¬ë°”ë¥¸ ì˜ˆ: "ê·¸, ê·¸, ê·¸ë˜ì„œ ì €, ì €í¬ê°€..."
- âŒ ì˜ëª»ëœ ì˜ˆ: "ê·¸ë˜ì„œ ì €í¬ê°€..." (ë”ë“¬ê±°ë¦¼ ì œê±°ë¨)

### 2. í™”ì ë ˆì´ë¸” ê·œì¹™
"í™”ì1", "í™”ì2" ëŒ€ì‹  **ì‹¤ì œ ì—­í• ê³¼ ì´ë¦„**ì„ ì‚¬ìš©í•˜ì„¸ìš”:

- **ì‚¬íšŒì**: í† ë¡  ì§„í–‰ì â†’ speaker: "ì‚¬íšŒì" ë˜ëŠ” ì‹¤ì œ ì´ë¦„
- **í›„ë³´ì**: ì˜ìƒì—ì„œ ì´ë¦„ì´ ì–¸ê¸‰ë˜ê±°ë‚˜ í™”ë©´ì— í‘œì‹œë˜ë©´ í•´ë‹¹ ì´ë¦„ ì‚¬ìš©
  - ì˜ˆ: "ê¸°í˜¸ 1ë²ˆ í™ê¸¸ë™ì…ë‹ˆë‹¤" â†’ speaker: "í™ê¸¸ë™"
  - í™”ë©´ ìë§‰ì— "í™ê¸¸ë™ í›„ë³´" í‘œì‹œ â†’ speaker: "í™ê¸¸ë™"
- **ì´ë¦„ ëª¨ë¥¼ ë•Œ**: "í›„ë³´1", "í›„ë³´2"ë¡œ ì‹œì‘, ì´ë¦„ ë°í˜€ì§€ë©´ ì†Œê¸‰ ì ìš©

### 3. ì •ì±…ëª… ì •í™• ì „ì‚¬ (í•µì‹¬!)
**ë°œìŒì´ ë­‰ê°œì ¸ë„ ì •ì±…ëª…ì€ ì •í™•í•˜ê²Œ** ì „ì‚¬í•˜ì„¸ìš”. ë§¥ë½ê³¼ í™”ë©´ ì •ë³´ë¡œ ì¶”ë¡ :

- **ì •ì±…/ë²•ì•ˆëª…**: í™”ë©´ì— í‘œì‹œëœ ì •í™•í•œ ëª…ì¹­ ì‚¬ìš©
  - ë°œí™”: "ì£¼ê±°ë³µì§€ë²•ì„..." (ë°œìŒ ë¶ˆëª…í™•)
  - í™”ë©´: "ì£¼ê±°ë³µì§€ê¸°ë³¸ë²•" í‘œì‹œ â†’ "ì£¼ê±°ë³µì§€ê¸°ë³¸ë²•ì„..."
- **ìˆ«ì/ì˜ˆì‚°**: í™”ë©´ì˜ ì¸í¬ê·¸ë˜í”½ ì°¸ê³ í•˜ì—¬ ì •í™•íˆ
  - ë°œí™”: "ë°±ì–µ... ì•„ë‹ˆ ì²œì–µ ì˜ˆì‚°..." (í˜¼ë€)
  - í™”ë©´: "1,000ì–µ ì›" í‘œì‹œ â†’ í™”ë©´ ê¸°ì¤€ìœ¼ë¡œ "1,000ì–µ ì› ì˜ˆì‚°..."
- **ê³µì•½ëª…**: ë§¥ë½ìƒ ëª…í™•í•œ ê³µì•½ëª…ìœ¼ë¡œ ì „ì‚¬
  - ë°œí™”: "ê·¸ ë­ëƒ... ì²­ë…„ ì •ì±…..." (ë¶ˆëª…í™•)
  - ë§¥ë½: ì²­ë…„ì£¼ê±°ì§€ì›ì •ì±… ë…¼ì˜ ì¤‘ â†’ "ì²­ë…„ì£¼ê±°ì§€ì›ì •ì±…..."

### 4. ë§íˆ¬/ì–´íˆ¬ ë³´ì¡´
- "~ì…ë‹ˆë‹¤", "~ê±°ë“ ìš”", "~ì–ì•„ìš”" ë“± **í™”ì ë§íˆ¬ ê·¸ëŒ€ë¡œ**
- ì‚¬íˆ¬ë¦¬, ë¹„ê²©ì‹ì²´ ëª¨ë‘ **ì›ë³¸ ê·¸ëŒ€ë¡œ**
- âš ï¸ ì ˆëŒ€ ë¬¸ì–´ì²´ë¡œ ë°”ê¾¸ì§€ ë§ ê²ƒ!

ì˜ˆì‹œ:
- ì›ë³¸: "ê·¸ë˜ì„œ ì €ëŠ”ìš”, ì–´... ê·¸ ë­ëƒ, ì£¼ê±°ë³µ... ì£¼ê±°ë³µì§€ë²•ì„ ê°œì •í•´ì„œìš”..."
- ì •í™•í•œ ì „ì‚¬: "ê·¸ë˜ì„œ ì €ëŠ”ìš”, ì–´... ê·¸ ë­ëƒ, ì£¼ê±°ë³µì§€ê¸°ë³¸ë²•ì„ ê°œì •í•´ì„œìš”..."
  (ë”ë“¬ê±°ë¦¼ ìœ ì§€ + ì •ì±…ëª… ì •í™•)
"""

        media_type = "ì˜ìƒ" if use_video_mode else "ì˜¤ë””ì˜¤"
        return f"""ë‹¹ì‹ ì€ ì „ë¬¸ ì „ì‚¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ {media_type}ë¥¼ ì •í™•í•˜ê²Œ ì „ì‚¬í•˜ì„¸ìš”.

## ìš”êµ¬ì‚¬í•­
1. ì–¸ì–´: {language} (í•œêµ­ì–´)
2. {speaker_hint}ê° í™”ìë¥¼ êµ¬ë¶„í•˜ì—¬ ë ˆì´ë¸”ë§í•˜ì„¸ìš”.
3. íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•˜ì„¸ìš”.
4. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
{video_mode_section}{filler_removal_section}{election_debate_section}{proper_noun_section}
## ì¶œë ¥ í˜•ì‹ (JSON)
```json
{{
  "segments": [
    {{
      "start": 0.0,
      "end": 3.5,
      "speaker": "ì‚¬íšŒì",
      "text": "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ? ì˜¤ëŠ˜ í† ë¡ íšŒ ì‚¬íšŒë¥¼ ë§¡ì€ 000ì…ë‹ˆë‹¤."
    }},
    {{
      "start": 3.5,
      "end": 7.2,
      "speaker": "í™ê¸¸ë™",
      "text": "ì•ˆë…•í•˜ì„¸ìš”. ê¸°í˜¸ 1ë²ˆ í™ê¸¸ë™ì…ë‹ˆë‹¤."
    }}
  ],
  "num_speakers": 2,
  "language": "ko"
}}
```

## ì£¼ì˜ì‚¬í•­
- **ì¤‘ìš”**: íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” ë°˜ë“œì‹œ **ì´ˆ ë‹¨ìœ„ ìˆ«ì**ë¡œ í‘œì‹œ
  - ì˜¬ë°”ë¥¸ ì˜ˆ: 12.5, 125.3, 762.0
  - ì˜ëª»ëœ ì˜ˆ: "12:42", "1:25", "00:12:42"
  - 12ë¶„ 42ì´ˆ = 762ì´ˆ (12*60 + 42 = 762)
- í™”ìëŠ” "í™”ì1", "í™”ì2" í˜•ì‹ìœ¼ë¡œ ì¼ê´€ë˜ê²Œ ë ˆì´ë¸”ë§
- ì•Œì•„ë“£ê¸° ì–´ë ¤ìš´ ë¶€ë¶„ì€ [ë¶ˆëª…í™•] í‘œì‹œ
- ë¹„ì–¸ì–´ì  ì†Œë¦¬ëŠ” (ì›ƒìŒ), (ë°•ìˆ˜), (ì¹¨ë¬µ) ë“±ìœ¼ë¡œ í‘œì‹œ
- JSON ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."""

    def _normalize_timestamp(self, value, audio_duration: float = 0) -> float:
        """íƒ€ì„ìŠ¤íƒ¬í”„ ì •ê·œí™” - ë‹¤ì–‘í•œ í˜•ì‹ ì²˜ë¦¬"""
        if isinstance(value, (int, float)):
            ts = float(value)
            # ë¹„ì •ìƒì ìœ¼ë¡œ í° ê°’ ê°ì§€ (ì˜ˆ: 1242 ëŒ€ì‹  12:42ì˜ ì˜¤í•´ì„)
            if audio_duration > 0 and ts > audio_duration * 1.5:
                # MMSS í˜•ì‹ìœ¼ë¡œ í•´ì„ ì‹œë„ (1242 -> 12ë¶„ 42ì´ˆ -> 762ì´ˆ)
                if ts >= 100:
                    minutes = int(ts) // 100
                    seconds = int(ts) % 100
                    converted = minutes * 60 + seconds
                    if converted <= audio_duration * 1.2:
                        print(f"[Gemini] íƒ€ì„ìŠ¤íƒ¬í”„ ë³´ì •: {ts} -> {converted}ì´ˆ")
                        return float(converted)
            return ts
        elif isinstance(value, str):
            # "12:42" ë˜ëŠ” "00:12:42" í˜•ì‹ ì²˜ë¦¬
            if ':' in value:
                parts = value.split(':')
                try:
                    if len(parts) == 2:  # MM:SS
                        return float(parts[0]) * 60 + float(parts[1])
                    elif len(parts) == 3:  # HH:MM:SS
                        return float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2])
                except ValueError:
                    pass
            # ìˆ«ì ë¬¸ìì—´
            try:
                return float(value)
            except ValueError:
                return 0.0
        return 0.0

    def _parse_response(self, response_text: str, audio_duration: float = 0) -> dict:
        """ì‘ë‹µ íŒŒì‹±"""
        # JSON ë¸”ë¡ ì¶”ì¶œ
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # JSON ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì‹œë„
            json_str = response_text.strip()
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            if json_str.startswith('```'):
                json_str = re.sub(r'^```\w*\n?', '', json_str)
                json_str = re.sub(r'\n?```$', '', json_str)

        try:
            data = json.loads(json_str)
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì •ê·œí™”
            if "segments" in data:
                for seg in data["segments"]:
                    seg["start"] = self._normalize_timestamp(seg.get("start", 0), audio_duration)
                    seg["end"] = self._normalize_timestamp(seg.get("end", 0), audio_duration)
            return data
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ íŒŒì‹± ì‹œë„
            return self._fallback_parse(response_text)

    def _fallback_parse(self, text: str) -> dict:
        """í´ë°± íŒŒì‹± - í…ìŠ¤íŠ¸ì—ì„œ ëŒ€í™” ì¶”ì¶œ"""
        segments = []
        lines = text.strip().split('\n')
        current_time = 0.0

        # íŒ¨í„´: [í™”ìN] í…ìŠ¤íŠ¸ ë˜ëŠ” í™”ìN: í…ìŠ¤íŠ¸
        pattern = re.compile(r'(?:\[?(í™”ì\d+|Speaker\s*\d+)\]?[:\s]+)?(.+)', re.IGNORECASE)

        for line in lines:
            line = line.strip()
            if not line:
                continue

            match = pattern.match(line)
            if match:
                speaker = match.group(1) or "í™”ì1"
                text_content = match.group(2).strip()

                if text_content:
                    # ëŒ€ëµì ì¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì • (ë‹¨ì–´ë‹¹ 0.3ì´ˆ)
                    word_count = len(text_content.split())
                    duration = max(1.0, word_count * 0.3)

                    segments.append({
                        "start": current_time,
                        "end": current_time + duration,
                        "speaker": speaker,
                        "text": text_content
                    })
                    current_time += duration + 0.2  # ê°„ê²©

        return {
            "segments": segments,
            "num_speakers": len(set(s["speaker"] for s in segments)),
            "language": "ko"
        }

    def _upload_to_gcs(self, file_path: Path) -> str:
        """íŒŒì¼ì„ GCSì— ì—…ë¡œë“œí•˜ê³  gs:// URI ë°˜í™˜"""
        try:
            from google.cloud import storage
            import uuid
            from datetime import datetime

            client = storage.Client()
            bucket = client.bucket(GCS_BUCKET_NAME)

            # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            unique_id = str(uuid.uuid4())[:8]
            blob_name = f"{timestamp}_{unique_id}_{file_path.name}"

            blob = bucket.blob(blob_name)
            blob.upload_from_filename(str(file_path))

            gs_uri = f"gs://{GCS_BUCKET_NAME}/{blob_name}"
            print(f"[GCS] ì—…ë¡œë“œ ì™„ë£Œ: {gs_uri}")
            return gs_uri

        except Exception as e:
            print(f"[GCS] ì—…ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì „í™˜")
            return None

    def _delete_from_gcs(self, gs_uri: str) -> None:
        """GCSì—ì„œ íŒŒì¼ ì‚­ì œ"""
        try:
            from google.cloud import storage

            # gs://bucket/path í˜•ì‹ì—ì„œ blob ì´ë¦„ ì¶”ì¶œ
            if gs_uri.startswith(f"gs://{GCS_BUCKET_NAME}/"):
                blob_name = gs_uri[len(f"gs://{GCS_BUCKET_NAME}/"):]
                client = storage.Client()
                bucket = client.bucket(GCS_BUCKET_NAME)
                blob = bucket.blob(blob_name)
                blob.delete()
                print(f"[GCS] ì‚­ì œ ì™„ë£Œ: {blob_name}")
        except Exception as e:
            print(f"[GCS] ì‚­ì œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

    def _get_audio_duration(self, audio_path: Path) -> float:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ ì¡°íšŒ (ì´ˆ)"""
        try:
            cmd = [
                "ffprobe",
                "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                str(audio_path)
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            if result.returncode != 0:
                return 0.0  # ì‹¤íŒ¨ ì‹œ 0 ë°˜í™˜
            return float(result.stdout.strip())
        except FileNotFoundError:
            # ffprobeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°
            print("[Gemini] ffprobe ì—†ìŒ - íŒŒì¼ ê¸¸ì´ ì¶”ì • ìƒëµ")
            return 0.0
        except (subprocess.TimeoutExpired, ValueError, Exception) as e:
            print(f"[Gemini] íŒŒì¼ ê¸¸ì´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0.0

    async def _call_with_retry(
        self,
        model,
        audio_input,
        prompt: str,
        audio_duration: float
    ):
        """
        Gemini API í˜¸ì¶œ (429 Rate Limit ì¬ì‹œë„ ë¡œì§ í¬í•¨)

        Args:
            model: Gemini GenerativeModel ì¸ìŠ¤í„´ìŠ¤
            audio_input: ì˜¤ë””ì˜¤ íŒŒì¼ ë˜ëŠ” GCS URI
            prompt: ì „ì‚¬ í”„ë¡¬í”„íŠ¸
            audio_duration: ì˜¤ë””ì˜¤ ê¸¸ì´ (íƒ€ì„ìŠ¤íƒ¬í”„ ë³´ì •ìš©)

        Returns:
            Gemini API ì‘ë‹µ
        """
        max_retries = self.config.max_retries
        base_delay = 30  # ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

        for attempt in range(max_retries):
            try:
                response = model.generate_content(
                    [audio_input, prompt],
                    generation_config=genai.GenerationConfig(
                        temperature=self.config.temperature,  # Gemini 3: 1.0 ê¶Œì¥
                        max_output_tokens=65536,  # ìµœëŒ€ ì¶œë ¥ í† í°
                    ),
                    request_options={"timeout": self.config.timeout}
                )
                return response

            except google_exceptions.ResourceExhausted as e:
                # 429 Rate Limit ì—ëŸ¬
                if attempt < max_retries - 1:
                    # ì§€ìˆ˜ ë°±ì˜¤í”„ + ì§€í„°
                    delay = base_delay * (2 ** attempt) + random.uniform(0, 10)
                    print(f"[Gemini] âš ï¸ Rate limit (429) - {delay:.0f}ì´ˆ í›„ ì¬ì‹œë„ ({attempt + 1}/{max_retries})")
                    time.sleep(delay)
                else:
                    print(f"[Gemini] âŒ Rate limit ì´ˆê³¼ - ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬")
                    raise RuntimeError(
                        f"Gemini API Rate Limit ì´ˆê³¼. {max_retries}íšŒ ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨. "
                        "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜, API í• ë‹¹ëŸ‰ì„ í™•ì¸í•˜ì„¸ìš”."
                    ) from e

            except google_exceptions.DeadlineExceeded as e:
                # íƒ€ì„ì•„ì›ƒ ì—ëŸ¬
                if attempt < max_retries - 1:
                    delay = 10 * (attempt + 1)
                    print(f"[Gemini] âš ï¸ íƒ€ì„ì•„ì›ƒ - {delay}ì´ˆ í›„ ì¬ì‹œë„ ({attempt + 1}/{max_retries})")
                    time.sleep(delay)
                else:
                    raise RuntimeError(
                        f"Gemini API íƒ€ì„ì•„ì›ƒ. ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    ) from e

            except Exception as e:
                # ê¸°íƒ€ ì—ëŸ¬ëŠ” ë°”ë¡œ raise
                error_str = str(e).lower()
                if "429" in error_str or "resource exhausted" in error_str or "quota" in error_str:
                    if attempt < max_retries - 1:
                        delay = base_delay * (2 ** attempt) + random.uniform(0, 10)
                        print(f"[Gemini] âš ï¸ Rate limit ê°ì§€ - {delay:.0f}ì´ˆ í›„ ì¬ì‹œë„ ({attempt + 1}/{max_retries})")
                        time.sleep(delay)
                    else:
                        raise RuntimeError(f"API Rate Limit ì´ˆê³¼: {e}") from e
                else:
                    raise

    async def transcribe(
        self,
        audio_path: str,
        language: str = "ko",
        num_speakers: Optional[int] = None,
        proper_nouns: Optional[List[str]] = None,
        use_video_mode: bool = False,
        original_video_path: Optional[str] = None,
        remove_fillers: bool = False,
        election_debate_mode: bool = False,
    ) -> TranscriptionResult:
        """
        Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤/ì˜ìƒ ì „ì‚¬

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ
            num_speakers: í™”ì ìˆ˜ íŒíŠ¸
            proper_nouns: ê³ ìœ ëª…ì‚¬/ì¸ëª… íŒíŠ¸ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["í™©ê¸ˆì„", "ì‚¼ì„±ì „ì"])
            use_video_mode: ì˜ìƒ ëª¨ë“œ (í™”ë©´ í…ìŠ¤íŠ¸ ì¸ì‹ í¬í•¨)
            original_video_path: ì›ë³¸ ì˜ìƒ íŒŒì¼ ê²½ë¡œ (ì˜ìƒ ëª¨ë“œì¼ ë•Œ ì‚¬ìš©)
            remove_fillers: í•„ëŸ¬(ì–´, ìŒ) ë° ë”ë“¬ê±°ë¦¼ ì œê±° ì—¬ë¶€
            election_debate_mode: ì„ ê±° í† ë¡ íšŒ ëª¨ë“œ (ì‚¬íšŒì/í›„ë³´ëª… êµ¬ë¶„, ì •ì±… ì •í™• ì „ì‚¬)

        Returns:
            TranscriptionResult ê°ì²´
        """
        audio_path = Path(audio_path)
        if not audio_path.exists():
            raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")

        # ì˜ìƒ ëª¨ë“œ ì„¤ì • (config ë˜ëŠ” íŒŒë¼ë¯¸í„°)
        use_video = use_video_mode or self.config.use_video_mode

        # ì˜ìƒ ëª¨ë“œì¼ ë•Œ ì›ë³¸ ì˜ìƒ ì‚¬ìš©
        media_path = audio_path
        if use_video and original_video_path:
            video_path = Path(original_video_path)
            if video_path.exists() and video_path.suffix.lower() in ['.mp4', '.mkv', '.avi', '.mov', '.webm']:
                media_path = video_path
                print(f"[Gemini] ğŸ¬ ì˜ìƒ ëª¨ë“œ í™œì„±í™” - í™”ë©´ í…ìŠ¤íŠ¸ ì¸ì‹ í¬í•¨")

        # íŒŒì¼ í¬ê¸° ë° ê¸¸ì´ í™•ì¸
        file_size_mb = media_path.stat().st_size / (1024 * 1024)
        audio_duration = self._get_audio_duration(media_path)
        print(f"[Gemini] íŒŒì¼ í¬ê¸°: {file_size_mb:.1f} MB, ê¸¸ì´: {audio_duration:.0f}ì´ˆ ({audio_duration/60:.1f}ë¶„)")

        if proper_nouns:
            print(f"[Gemini] ê³ ìœ ëª…ì‚¬ íŒíŠ¸: {', '.join(proper_nouns)}")

        if remove_fillers:
            print(f"[Gemini] ğŸ§¹ í•„ëŸ¬ ì œê±° ëª¨ë“œ í™œì„±í™”")

        if election_debate_mode:
            print(f"[Gemini] ğŸ—³ï¸ ì„ ê±° í† ë¡ íšŒ ëª¨ë“œ í™œì„±í™” (ì‚¬íšŒì/í›„ë³´ëª… êµ¬ë¶„)")

        # ì²­í¬ ë¶„í•  ì—¬ë¶€ ê²°ì • (ì˜ìƒ/ì˜¤ë””ì˜¤ ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ ì„ê³„ê°’)
        if use_video:
            # ì˜ìƒ ëª¨ë“œ: 45ë¶„ ì œí•œ â†’ 30ë¶„ ì„ê³„ê°’
            chunk_threshold = VIDEO_CHUNK_THRESHOLD_SECONDS
            needs_chunking = (
                self.config.enable_chunking and
                audio_duration > chunk_threshold
            )
            if needs_chunking:
                print(f"[Gemini] ğŸ¬ ì˜ìƒ ë¶„í•  ëª¨ë“œ - {audio_duration/60:.0f}ë¶„ ì˜ìƒì„ ì²­í¬ë¡œ ë¶„í•  (ì˜ìƒ ëª¨ë“œ ìœ ì§€)")
                return await self._transcribe_with_video_chunks(
                    media_path, language, num_speakers, proper_nouns, remove_fillers, election_debate_mode
                )
        else:
            # ì˜¤ë””ì˜¤ ëª¨ë“œ: 8.4ì‹œê°„ ì œí•œ â†’ 4ì‹œê°„ ì„ê³„ê°’
            chunk_threshold = AUDIO_CHUNK_THRESHOLD_SECONDS
            needs_chunking = (
                self.config.enable_chunking and
                (audio_duration > chunk_threshold or file_size_mb > 1000)  # 1GB ì´ìƒ
            )
            if needs_chunking:
                print(f"[Gemini] ğŸµ ê¸´ ì˜¤ë””ì˜¤ ê°ì§€ ({audio_duration/3600:.1f}ì‹œê°„) - ì²­í¬ ë¶„í•  ì²˜ë¦¬")
                return await self._transcribe_with_chunks(audio_path, language, num_speakers, proper_nouns, remove_fillers, election_debate_mode)

        # ì¼ë°˜ ì „ì‚¬ (ë¶„í•  ë¶ˆí•„ìš”)
        return await self._transcribe_single(
            media_path, language, num_speakers, proper_nouns, use_video, remove_fillers, election_debate_mode
        )

    async def _transcribe_with_chunks(
        self,
        audio_path: Path,
        language: str,
        num_speakers: Optional[int],
        proper_nouns: Optional[List[str]] = None,
        remove_fillers: bool = False,
        election_debate_mode: bool = False
    ) -> TranscriptionResult:
        """ì²­í¬ ë¶„í• ì„ ì‚¬ìš©í•œ ê¸´ ì˜¤ë””ì˜¤ ì „ì‚¬"""
        # ì²­í¬ ë¶„í•  ì„¤ì •
        chunk_config = ChunkConfig(
            target_chunk_duration=600,  # ëª©í‘œ 10ë¶„
            max_chunk_duration=900,     # ìµœëŒ€ 15ë¶„
            silence_threshold_db=-40,
            min_silence_duration=0.5,
            overlap_duration=2.0
        )
        chunker = AudioChunker(chunk_config)

        # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì²­í¬ ìƒì„±
        with tempfile.TemporaryDirectory(prefix="vtt_chunks_") as tmp_dir:
            chunks = chunker.split_audio(audio_path, tmp_dir)
            total_chunks = len(chunks)
            print(f"[Gemini] {total_chunks}ê°œ ì²­í¬ë¡œ ë¶„í• ë¨")

            # í™”ì ì´ë¦„ ëˆ„ì  (ì²­í¬ ê°„ ì „ë‹¬ìš©)
            discovered_speakers: set = set()
            if proper_nouns:
                discovered_speakers.update(proper_nouns)

            # ê° ì²­í¬ ì „ì‚¬
            chunk_results = []
            for i, chunk in enumerate(chunks):
                print(f"[Gemini] â”â”â” ì²­í¬ {i+1}/{total_chunks} ì „ì‚¬ ì‹œì‘ â”â”â”")
                print(f"[Gemini]   ğŸ“ êµ¬ê°„: {chunk.start_time:.0f}ì´ˆ ~ {chunk.end_time:.0f}ì´ˆ ({chunk.duration:.0f}ì´ˆ)")

                # í˜„ì¬ê¹Œì§€ ë°œê²¬ëœ í™”ì ì´ë¦„ì„ íŒíŠ¸ë¡œ ì „ë‹¬
                current_hints = list(discovered_speakers) if discovered_speakers else None
                if current_hints:
                    print(f"[Gemini]   ğŸ‘¥ í™”ì íŒíŠ¸: {', '.join(current_hints)}")

                try:
                    result = await self._transcribe_single(
                        chunk.path, language, num_speakers, current_hints,
                        False, remove_fillers, election_debate_mode
                    )

                    # dict í˜•íƒœë¡œ ë³€í™˜
                    chunk_result = {
                        "segments": [
                            {
                                "start": seg.start,
                                "end": seg.end,
                                "text": seg.text,
                                "speaker": seg.speaker
                            }
                            for seg in result.segments
                        ],
                        "language": result.language,
                        "num_speakers": result.num_speakers
                    }
                    chunk_results.append(chunk_result)

                    # ìƒˆë¡œ ë°œê²¬ëœ í™”ì ì´ë¦„ ì¶”ì¶œ (ë‹¤ìŒ ì²­í¬ì— ì „ë‹¬)
                    for seg in result.segments:
                        if seg.speaker and seg.speaker not in ["í™”ì1", "í™”ì2", "í™”ì3", "í™”ì4", "í™”ì5",
                                                                "í›„ë³´1", "í›„ë³´2", "í›„ë³´3", "í›„ë³´4", "í›„ë³´5",
                                                                "ì‚¬íšŒì", "ì§„í–‰ì", "Unknown"]:
                            if seg.speaker not in discovered_speakers:
                                discovered_speakers.add(seg.speaker)
                                print(f"[Gemini]   ğŸ†• ìƒˆ í™”ì ë°œê²¬: {seg.speaker}")

                    print(f"[Gemini] âœ… ì²­í¬ {i+1}/{total_chunks} ì™„ë£Œ ({len(result.segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")

                except Exception as e:
                    print(f"[Gemini] âŒ ì²­í¬ {i+1} ì „ì‚¬ ì‹¤íŒ¨: {e}")
                    chunk_results.append({"segments": [], "language": language})

            # ê²°ê³¼ ë³‘í•©
            merged = merge_transcriptions(chunk_results, chunks, chunk_config.overlap_duration)

            # Segment ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            segments = []
            for seg_data in merged.get("segments", []):
                segments.append(Segment(
                    start=float(seg_data.get("start", 0)),
                    end=float(seg_data.get("end", 0)),
                    text=seg_data.get("text", ""),
                    speaker=seg_data.get("speaker"),
                    confidence=None
                ))

            # ì „ì²´ ê¸¸ì´ ê³„ì‚°
            total_duration = segments[-1].end if segments else 0.0

            return TranscriptionResult(
                segments=segments,
                language=merged.get("language", language),
                duration=total_duration,
                num_speakers=merged.get("num_speakers", 1),
                engine=self.name,
                model=self.config.model
            )

    async def _transcribe_with_video_chunks(
        self,
        video_path: Path,
        language: str,
        num_speakers: Optional[int],
        proper_nouns: Optional[List[str]] = None,
        remove_fillers: bool = False,
        election_debate_mode: bool = False
    ) -> TranscriptionResult:
        """ì˜ìƒ ë¶„í• ì„ ì‚¬ìš©í•œ ì „ì‚¬ (ì˜ìƒ ëª¨ë“œ ìœ ì§€)

        ì˜ìƒì„ 20ë¶„ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ê° ì²­í¬ë¥¼ ì˜ìƒ ëª¨ë“œë¡œ ì²˜ë¦¬.
        í™”ë©´ í…ìŠ¤íŠ¸ ì¸ì‹ì„ ìœ ì§€í•˜ë©´ì„œ 45ë¶„ ì œí•œì„ ì¤€ìˆ˜.
        """
        # ì˜ìƒ ê¸¸ì´ í™•ì¸
        video_duration = self._get_audio_duration(video_path)
        target_chunk_duration = 1200  # 20ë¶„ (45ë¶„ ì œí•œì˜ ì•ˆì „ ë§ˆì§„)

        # ì²­í¬ ìˆ˜ ê³„ì‚°
        num_chunks = max(1, int(video_duration / target_chunk_duration) + 1)
        chunk_duration = video_duration / num_chunks

        print(f"[Gemini] ğŸ¬ ì˜ìƒ {num_chunks}ê°œ ì²­í¬ë¡œ ë¶„í•  (ê° {chunk_duration/60:.1f}ë¶„)")

        # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì˜ìƒ ì²­í¬ ìƒì„±
        with tempfile.TemporaryDirectory(prefix="vtt_video_chunks_") as tmp_dir:
            video_chunks = []

            # FFmpegë¡œ ì˜ìƒ ë¶„í• 
            for i in range(num_chunks):
                start_time = i * chunk_duration
                # ë§ˆì§€ë§‰ ì²­í¬ëŠ” ëê¹Œì§€
                end_time = min((i + 1) * chunk_duration, video_duration)
                duration = end_time - start_time

                chunk_path = Path(tmp_dir) / f"chunk_{i:03d}{video_path.suffix}"

                # FFmpeg ì˜ìƒ ë¶„í•  ëª…ë ¹
                cmd = [
                    "ffmpeg",
                    "-i", str(video_path),
                    "-ss", str(start_time),
                    "-t", str(duration),
                    "-c", "copy",  # ë¹ ë¥¸ ë³µì‚¬ (ì¬ì¸ì½”ë”© ì—†ìŒ)
                    "-y",
                    str(chunk_path)
                ]

                try:
                    subprocess.run(cmd, capture_output=True, timeout=300, check=True)
                    video_chunks.append({
                        "path": chunk_path,
                        "start_time": start_time,
                        "end_time": end_time,
                        "duration": duration,
                        "index": i
                    })
                    print(f"[Gemini]   âœ… ì²­í¬ {i+1}/{num_chunks}: {start_time/60:.1f}ë¶„ ~ {end_time/60:.1f}ë¶„")
                except subprocess.CalledProcessError as e:
                    print(f"[Gemini]   âŒ ì²­í¬ {i+1} ë¶„í•  ì‹¤íŒ¨: {e}")
                    continue

            if not video_chunks:
                raise RuntimeError("ì˜ìƒ ë¶„í•  ì‹¤íŒ¨ - ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ")

            # í™”ì ì´ë¦„ ëˆ„ì 
            discovered_speakers: set = set()
            if proper_nouns:
                discovered_speakers.update(proper_nouns)

            # ê° ì˜ìƒ ì²­í¬ ì „ì‚¬ (ì˜ìƒ ëª¨ë“œ ìœ ì§€!)
            chunk_results = []
            for chunk in video_chunks:
                print(f"[Gemini] â”â”â” ì˜ìƒ ì²­í¬ {chunk['index']+1}/{len(video_chunks)} ì „ì‚¬ ì‹œì‘ â”â”â”")
                print(f"[Gemini]   ğŸ“ êµ¬ê°„: {chunk['start_time']/60:.1f}ë¶„ ~ {chunk['end_time']/60:.1f}ë¶„")

                current_hints = list(discovered_speakers) if discovered_speakers else None

                try:
                    # ì˜ìƒ ëª¨ë“œ ìœ ì§€! (use_video_mode=True)
                    result = await self._transcribe_single(
                        chunk["path"], language, num_speakers, current_hints,
                        True,  # ğŸ¬ ì˜ìƒ ëª¨ë“œ ìœ ì§€
                        remove_fillers, election_debate_mode
                    )

                    # íƒ€ì„ìŠ¤íƒ¬í”„ ì˜¤í”„ì…‹ ì ìš©
                    chunk_result = {
                        "segments": [
                            {
                                "start": seg.start + chunk["start_time"],  # ì›ë³¸ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
                                "end": seg.end + chunk["start_time"],
                                "text": seg.text,
                                "speaker": seg.speaker
                            }
                            for seg in result.segments
                        ],
                        "language": result.language,
                        "num_speakers": result.num_speakers
                    }
                    chunk_results.append(chunk_result)

                    # ìƒˆ í™”ì ë°œê²¬ ì‹œ ì¶”ê°€
                    for seg in result.segments:
                        if seg.speaker and seg.speaker not in ["í™”ì1", "í™”ì2", "í™”ì3", "í™”ì4", "í™”ì5",
                                                                "í›„ë³´1", "í›„ë³´2", "ì‚¬íšŒì", "ì§„í–‰ì", "Unknown"]:
                            if seg.speaker not in discovered_speakers:
                                discovered_speakers.add(seg.speaker)
                                print(f"[Gemini]   ğŸ†• ìƒˆ í™”ì ë°œê²¬: {seg.speaker}")

                    print(f"[Gemini] âœ… ì²­í¬ {chunk['index']+1} ì™„ë£Œ ({len(result.segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")

                except Exception as e:
                    print(f"[Gemini] âŒ ì²­í¬ {chunk['index']+1} ì „ì‚¬ ì‹¤íŒ¨: {e}")
                    chunk_results.append({"segments": [], "language": language})

            # ê²°ê³¼ ë³‘í•© (ì¤‘ë³µ ì œê±° ë¡œì§ ì ìš©)
            merged_segments = []
            for result in chunk_results:
                merged_segments.extend(result.get("segments", []))

            # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ ì •ë ¬
            merged_segments.sort(key=lambda x: x["start"])

            # Segment ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            segments = [
                Segment(
                    start=float(seg.get("start", 0)),
                    end=float(seg.get("end", 0)),
                    text=seg.get("text", ""),
                    speaker=seg.get("speaker"),
                    confidence=None
                )
                for seg in merged_segments
            ]

            total_duration = segments[-1].end if segments else 0.0

            return TranscriptionResult(
                segments=segments,
                language=language,
                duration=total_duration,
                num_speakers=len(discovered_speakers) if discovered_speakers else 1,
                engine=self.name,
                model=self.config.model
            )

    async def _transcribe_single(
        self,
        audio_path: Path,
        language: str,
        num_speakers: Optional[int],
        proper_nouns: Optional[List[str]] = None,
        use_video_mode: bool = False,
        remove_fillers: bool = False,
        election_debate_mode: bool = False
    ) -> TranscriptionResult:
        """ë‹¨ì¼ ì˜¤ë””ì˜¤/ì˜ìƒ íŒŒì¼ ì „ì‚¬ (ì²­í¬ ë¶„í•  ì—†ìŒ) - 429 ì—ëŸ¬ ì¬ì‹œë„ í¬í•¨"""
        file_size_mb = audio_path.stat().st_size / (1024 * 1024)
        audio_duration = self._get_audio_duration(audio_path)  # íƒ€ì„ìŠ¤íƒ¬í”„ ë³´ì •ìš©

        media_file = None

        # Files API ì‚¬ìš© (GCS ë°©ì‹ ë¹„í™œì„±í™” - API í˜¸í™˜ì„± ë¬¸ì œ)
        print(f"[Gemini] Files API ì—…ë¡œë“œ ì¤‘... ({file_size_mb:.1f} MB)")
        media_file = genai.upload_file(str(audio_path))

        # íŒŒì¼ì´ ACTIVE ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        while media_file.state.name == "PROCESSING":
            print(f"[Gemini] íŒŒì¼ ì²˜ë¦¬ ì¤‘... (ìƒíƒœ: {media_file.state.name})")
            time.sleep(2)
            media_file = genai.get_file(media_file.name)

        if media_file.state.name != "ACTIVE":
            raise RuntimeError(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {media_file.state.name}")

        print(f"[Gemini] íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ (ìƒíƒœ: ACTIVE)")
        media_input = media_file

        # ëª¨ë¸ ìƒì„± ë° ì „ì‚¬
        model = genai.GenerativeModel(self.config.model)
        prompt = self._build_prompt(num_speakers, language, proper_nouns, use_video_mode, remove_fillers, election_debate_mode)

        # ì „ì‚¬ ìš”ì²­ (429 ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        mode_str = "ì˜ìƒ ëª¨ë“œ (í™”ë©´ ì°¸ê³ )" if use_video_mode else "ì˜¤ë””ì˜¤ ëª¨ë“œ"
        print(f"[Gemini] ì „ì‚¬ ì‹œì‘... ({mode_str})")
        response = await self._call_with_retry(
            model, media_input, prompt, audio_duration
        )
        print(f"[Gemini] ì „ì‚¬ ì™„ë£Œ")

        # ì‘ë‹µ íŒŒì‹± (ì˜¤ë””ì˜¤ ê¸¸ì´ ì „ë‹¬í•˜ì—¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë³´ì •)
        result_data = self._parse_response(response.text, audio_duration)

        # Segment ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        segments = []
        for seg_data in result_data.get("segments", []):
            segments.append(Segment(
                start=float(seg_data.get("start", 0)),
                end=float(seg_data.get("end", 0)),
                text=seg_data.get("text", ""),
                speaker=seg_data.get("speaker"),
                confidence=seg_data.get("confidence")
            ))

        # íŒŒì¼ ì •ë¦¬
        if media_file:
            try:
                genai.delete_file(media_file.name)
            except Exception:
                pass  # ì‚­ì œ ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ

        # ì „ì²´ ê¸¸ì´ ê³„ì‚°
        total_duration = segments[-1].end if segments else 0.0

        return TranscriptionResult(
            segments=segments,
            language=result_data.get("language", language),
            duration=total_duration,
            num_speakers=result_data.get("num_speakers", 1),
            engine=self.name,
            model=self.config.model
        )

    def _get_mime_type(self, file_path: Path) -> str:
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ MIME íƒ€ì… ë°˜í™˜"""
        mime_types = {
            ".mp3": "audio/mpeg",
            ".wav": "audio/wav",
            ".m4a": "audio/mp4",
            ".flac": "audio/flac",
            ".ogg": "audio/ogg",
            ".mp4": "video/mp4",
            ".mkv": "video/x-matroska",
            ".avi": "video/x-msvideo",
            ".mov": "video/quicktime",
        }
        return mime_types.get(file_path.suffix.lower(), "audio/mpeg")

    async def health_check(self) -> bool:
        """API ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            model = genai.GenerativeModel(self.config.model)
            response = model.generate_content("Hello")
            return bool(response.text)
        except Exception:
            return False
